{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../imgs/logo.png\" width=\"20%\" align=\"right\" style=\"margin:0px 20px\">\n",
    "\n",
    "\n",
    "# Evolutionary Computation\n",
    "\n",
    "## 5.3 Deep Neuroevolution\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" align=\"left\" src=\"https://i.creativecommons.org/l/by-sa/4.0/80x15.png\" /></a>&nbsp;| Dennis G. Wilson | <a href=\"https://d9w.github.io/evolution/\">https://d9w.github.io/evolution/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neuroevolution\n",
    "\n",
    "Artificial neural networks are commonly used today in many applications, from phone apps to automatic piloting systems to search engines. These machine learning models contain many parameters and are usually optimized with stochastic gradient descent. However, evolutionary strategies can also be a great tool for optimizing neural network parameters, especially when there isn't a clear direction the training of the network should take. This is the case for reinforcement learning, so we'll look at a classic RL task in this section.\n",
    "\n",
    "Because of the success of deep learning, where neural network architectures are \"deep\" by having many layers, this field is sometimes called deep neuroevolution. However, remember from tutorial 4 that researchers have been evolving neural networks long before the advent of deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In today's notebook, I'll be using some Python RL environments and using PyCall to interact with them in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "using PyCall\n",
    "using Conda\n",
    "using Flux\n",
    "include(\"cmaes.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can write a construction method which just uses zeros as all weights and biases. We'll fill these with the genetic information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my_CNN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct convol\n",
    "    w ::AbstractArray{Float64}\n",
    "    b ::AbstractArray{Float64}\n",
    "end\n",
    "\n",
    "struct my_CNN\n",
    "    c1 :: convol\n",
    "    c2 :: convol\n",
    "end\n",
    "\n",
    "function my_CNN(f1::Int,c1_in::Int,c1_out::Int,f2::Int,c2_in::Int,c2_out::Int)\n",
    "    c1 = convol(zeros(f1,f1,c1_in,c1_out),zeros(c1_out))\n",
    "    c2 = convol(zeros(f2,f2,c2_in,c2_out),zeros(c2_out))\n",
    "    my_CNN(c1,c2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we'll use our network to compute, passing an input in before the first layer and recording the activation of the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "compute_cnn (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function compute_cnn(ann,inputs)\n",
    "    y = Flux.Conv(ann.c1.w,ann.c1.b,σ;stride=3)(inputs)\n",
    "    y = MaxPool((2,2),stride=2)(y)\n",
    "    y = Flux.Conv(ann.c2.w,ann.c2.b,σ;stride=3)(y)\n",
    "    y = MeanPool((2,2),stride=4)(y)\n",
    "    y = flatten(y)\n",
    "    y = (y .> 0.5) .* 1 \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since all weights and biases are zeros, if we pass in zeros we should also get out zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now that we have an ANN, let's test it. We'll evaluate individuals in the CartPole environment, where they must balance a pole on a cart to keep it upright. The actions our agent can take are to move the cart either right or left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <module 'retro' from 'C:\\\\Users\\\\Kinza\\\\.julia\\\\conda\\\\3\\\\lib\\\\site-packages\\\\retro\\\\__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retro = pyimport_conda(\"retro\",\"gym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll run an entire episode, which terminates whenever the pole falls to a certain angle from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "play_env (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function play_env(ann; render=false)\n",
    "    env = retro.make(\"SonicTheHedgehog-Genesis\",\"GreenHillZone.Act1\")\n",
    "    ob = env.reset()\n",
    "    total_reward = 0.0\n",
    "    done = false\n",
    "    \n",
    "    #inx, iny, inc = env.observation_space.shape\n",
    "    #inx = floor(Int,inx/8)\n",
    "    #iny = floor(Int,iny/8)\n",
    "    \n",
    "    max_fitness = 0\n",
    "    fitness = 0\n",
    "    counter = 0\n",
    "    xpos = 0\n",
    "    xpos_max = 0\n",
    "    frame = 0\n",
    "    while ~done\n",
    "        if render\n",
    "            frame+=1\n",
    "            env.render()\n",
    "        end\n",
    "        \n",
    "        ob = Flux.unsqueeze(ob,4)\n",
    "        action = compute_cnn(ann,ob)\n",
    "        println(\"action = \",action)\n",
    "        \n",
    "        ob, reward, done, info = env.step(action)\n",
    "    \n",
    "        fitness += reward\n",
    "\n",
    "        xpos = info[\"x\"]\n",
    "        xpos_end = info[\"screen_x_end\"]\n",
    "\n",
    "\n",
    "        if xpos > xpos_max\n",
    "            fitness += 1\n",
    "            xpos_max = xpos\n",
    "        end\n",
    "\n",
    "        if xpos == xpos_end && xpos > 500\n",
    "            fitness += 100000\n",
    "            done = True\n",
    "        end\n",
    "\n",
    "        if fitness > max_fitness\n",
    "            max_fitness = fitness\n",
    "            counter = 0\n",
    "        else\n",
    "            counter += 1\n",
    "        end\n",
    "\n",
    "        if done || counter == 500\n",
    "            done = true\n",
    "        end\n",
    "\n",
    "    end\n",
    "    \n",
    "    env.close()\n",
    "    fitness\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "With our zero network, this won't be able to last very long, as it is always taking a constant action of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's write a new constructor for our network which takes in genes and sets all of the network parameters. We'll then optimize these genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objective (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function my_CNN(genes::Array{Float64})\n",
    "    ann = my_CNN(12,3,4,8,4,1)\n",
    "    layers = [ann.c1.w, ann.c1.b, ann.c2.w, ann.c2.b]\n",
    "    L = 1\n",
    "    j = 1\n",
    "    for i in eachindex(genes)\n",
    "        if j > length(layers[L])\n",
    "            L += 1\n",
    "            j = 1\n",
    "        end\n",
    "        layers[L][j] = genes[i]\n",
    "        j += 1\n",
    "    end\n",
    "    ann\n",
    "end\n",
    "\n",
    "function objective(genes::Array{Float64})\n",
    "    ann = my_CNN(genes)\n",
    "    -play_env(ann;render=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The objective function is then just to create an ANN and evaluate its performance on an episode of the CartPole benchmark. Because CMA-ES is minimizing, we'll return the negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how many genes we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 12*12*3*4+4+8*8*4*1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can try a random individual, maybe it will do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use the CMAES function we defined in the last notebook and optimize for just a few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We might notice that our results go down. Remember that CMA-ES is not elitist! We should keep an external archive of the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation = 1 fitness = 261.0 elapsed time = 178.49200010299683\n",
      "generation = 2 fitness = 823.0 elapsed time = 273.9390001296997\n",
      "generation = 3 fitness = 305.0 elapsed time = 424.01399993896484\n",
      "generation = 4 fitness = 210.0 elapsed time = 364.4279999732971\n",
      "generation = 5 fitness = 261.0 elapsed time = 436.0789999961853\n",
      "generation = 6 fitness = 180.0 elapsed time = 324.42199993133545\n",
      "generation = 7 fitness = 502.0 elapsed time = 517.5539999008179\n",
      "generation = 8 fitness = 176.0 elapsed time = 283.10199999809265\n",
      "generation = 9 fitness = 489.0 elapsed time = 535.4729998111725\n",
      "generation = 10 fitness = 199.0 elapsed time = 568.6829998493195\n",
      "generation = 11 fitness = 222.0 elapsed time = 385.01599979400635\n",
      "generation = 12 fitness = 499.0 elapsed time = 364.5420000553131\n",
      "generation = 13 fitness = 320.0 elapsed time = 372.9069998264313\n",
      "generation = 14 fitness = 259.0 elapsed time = 436.710000038147\n",
      "generation = 15 fitness = 198.0 elapsed time = 349.6819999217987\n",
      "generation = 16 fitness = 216.0 elapsed time = 361.51700019836426\n",
      "generation = 17 fitness = 197.0 elapsed time = 355.3819999694824\n",
      "generation = 18 fitness = 199.0 elapsed time = 349.3599998950958\n",
      "generation = 19 fitness = 147.0 elapsed time = 340.30400013923645\n",
      "generation = 20 fitness = 81.0 elapsed time = 387.2389998435974\n",
      "generation = 21 fitness = 378.0 elapsed time = 359.54900002479553\n",
      "generation = 22 fitness = 441.0 elapsed time = 328.85400009155273\n",
      "generation = 23 fitness = 81.0 elapsed time = 296.4839999675751\n",
      "generation = 24 fitness = 407.0 elapsed time = 326.9579999446869\n",
      "generation = 25 fitness = 417.0 elapsed time = 484.75300002098083\n",
      "generation = 26 fitness = 307.0 elapsed time = 373.4370000362396\n",
      "generation = 27 fitness = 273.0 elapsed time = 417.60700011253357\n",
      "generation = 28 fitness = 480.0 elapsed time = 405.27099990844727\n",
      "generation = 29 fitness = 189.0 elapsed time = 271.3220000267029\n",
      "generation = 30 fitness = 200.0 elapsed time = 291.94799995422363\n",
      "generation = 31 fitness = 384.0 elapsed time = 286.9930000305176\n",
      "generation = 32 fitness = 174.0 elapsed time = 259.6050000190735\n",
      "generation = 33 fitness = 513.0 elapsed time = 295.63499999046326\n",
      "generation = 34 fitness = 36.0 elapsed time = 305.37000012397766\n",
      "generation = 35 fitness = 109.0 elapsed time = 312.3789999485016\n",
      "generation = 36 fitness = 519.0 elapsed time = 321.595999956131\n",
      "generation = 37 fitness = 40.0 elapsed time = 300.50600004196167\n",
      "generation = 38 fitness = 311.0 elapsed time = 291.3619999885559\n",
      "generation = 39 fitness = 322.0 elapsed time = 326.99900007247925\n",
      "generation = 40 fitness = 380.0 elapsed time = 353.7279999256134\n",
      "generation = 41 fitness = 374.0 elapsed time = 291.8120000362396\n",
      "generation = 42 fitness = 190.0 elapsed time = 265.87400007247925\n",
      "generation = 43 fitness = 162.0 elapsed time = 22492.12800002098\n",
      "generation = 44 fitness = 173.0 elapsed time = 124.50300002098083\n"
     ]
    },
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled), ::Base.RefValue{Task}) at .\\task.jl:654",
      " [2] wait() at .\\task.jl:710",
      " [3] wait(::Base.GenericCondition{Base.Threads.SpinLock}) at .\\condition.jl:106",
      " [4] _wait(::Task) at .\\task.jl:238",
      " [5] wait(::Task) at .\\task.jl:265",
      " [6] macro expansion at .\\threadingconstructs.jl:69 [inlined]",
      " [7] conv_im2col!(::Array{Float64,5}, ::Array{Float64,5}, ::Array{Float64,5}, ::DenseConvDims{3,(8, 8, 1),4,1,(3, 3, 1),(0, 0, 0, 0, 0, 0),(1, 1, 1),false}; col::Array{Float64,3}, alpha::Float64, beta::Float64) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\impl\\conv_im2col.jl:49",
      " [8] conv_im2col! at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\impl\\conv_im2col.jl:30 [inlined]",
      " [9] #conv!#41 at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:53 [inlined]",
      " [10] conv!(::Array{Float64,5}, ::Array{Float64,5}, ::Array{Float64,5}, ::DenseConvDims{3,(8, 8, 1),4,1,(3, 3, 1),(0, 0, 0, 0, 0, 0),(1, 1, 1),false}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:53",
      " [11] conv!(::Array{Float64,4}, ::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:70",
      " [12] conv! at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:70 [inlined]",
      " [13] conv(::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:116",
      " [14] conv(::Array{Float64,4}, ::Array{Float64,4}, ::DenseConvDims{2,(8, 8),4,1,(3, 3),(0, 0, 0, 0),(1, 1),false}) at C:\\Users\\Kinza\\.julia\\packages\\NNlib\\FAI3o\\src\\conv.jl:114",
      " [15] (::Conv{2,4,typeof(σ),Array{Float64,4},Array{Float64,1}})(::Array{Float64,4}) at C:\\Users\\Kinza\\.julia\\packages\\Flux\\f1bXf\\src\\layers\\conv.jl:137",
      " [16] compute_cnn(::my_CNN, ::Array{UInt8,4}) at .\\In[3]:4",
      " [17] play_env(::my_CNN; render::Bool) at .\\In[5]:24",
      " [18] objective(::Array{Float64,1}) at .\\In[6]:19",
      " [19] step!(::CMAES, ::typeof(objective)) at C:\\Users\\Kinza\\Documents\\GitHub\\evolution\\5_strategies\\cmaes.jl:47",
      " [20] top-level scope at .\\In[10]:8"
     ]
    }
   ],
   "source": [
    "best = nothing\n",
    "best_fit = -Inf\n",
    "c = CMAES(N=N, µ=20, λ=20, τ=sqrt(N), τ_c=N^2, τ_σ=sqrt(N))\n",
    "i=0\n",
    "while best_fit <000 \n",
    "    i+=1\n",
    "    start = time()\n",
    "    step!(c, objective)\n",
    "    bestind = argmin(c.F_λ)\n",
    "    maxfit = -c.F_λ[bestind]\n",
    "    print(\"generation = \",i, \", fitness = \", maxfit)\n",
    "    if maxfit > best_fit\n",
    "        best = copy(c.offspring[bestind])\n",
    "        best_fit = maxfit\n",
    "    end\n",
    "    println(\", elapsed time = \",time()-start)\n",
    "end\n",
    "println(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally, we can see how the CMA-ES optimized invidual does on this benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching my_CNN(::Nothing)\nClosest candidates are:\n  my_CNN(::Any, !Matched::Any) at In[2]:7\n  my_CNN(!Matched::convol, !Matched::convol) at In[2]:7\n  my_CNN(!Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64) at In[2]:12\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching my_CNN(::Nothing)\nClosest candidates are:\n  my_CNN(::Any, !Matched::Any) at In[2]:7\n  my_CNN(!Matched::convol, !Matched::convol) at In[2]:7\n  my_CNN(!Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64, !Matched::Int64) at In[2]:12\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[9]:1"
     ]
    }
   ],
   "source": [
    "ann = my_CNN(best)\n",
    "play_env(ann; render=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Exercise</b>\n",
    "    <br/>\n",
    "    We were sort of cheating before. This neural network only learned how to do well on one individual, the one which comes from seeing the environment with 0. Test is on an environment with a different seed. Does it still do well? Finally, re-run the evaluation, but don't use a random seed, or change it every time. What is the impact of a stochastic fitness on evolution?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
